# -*- coding: utf-8 -*-
"""Zillow analysis using site's API

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1egtlCEPK1aRL8BwuaDNwhDpJwD835oTe
"""

from google.colab import drive,files
import pandas as pd
import requests
import json
import time

pd.set_option('display.max_columns',None)

city ='Norfolk'
state_abbr ='VA'
search_str = city.lower() + ', ' + state_abbr.lower()
print(search_str)
api_key='0ef80a1fc9msh5d3115c7673eb4bp1f8b41jsn2d43b66728b8'

url = "https://zillow-com1.p.rapidapi.com/propertyExtendedSearch"

querystring = {"location":search_str,"home_type":"Multi-family"}

headers = {
    'x-rapidapi-host': "zillow-com1.p.rapidapi.com",
    'x-rapidapi-key': api_key
    }

response = requests.request("GET", url, headers=headers, params=querystring)

df = response.json()

#Output that Zillow is providing
df

#Taking the json data and normalizing it in a pandas dataframe
df=pd.json_normalize(data=df["props"])

print("# of Columns:",len(df.columns))
print("# of Rows:", len(df))
df.head(2)

#To get more detail on each house, need to pass zpid from above to another api
zpid= df['zpid'].tolist()
zpid

#Now that we have each zpid, going to pass that id into the query string and then append to a blank list
property_info=[]
for i in zpid[11]:
  url = "https://zillow-com1.p.rapidapi.com/property"

  querystring = {"zpid":i}

  headers = {
      'x-rapidapi-host': "zillow-com1.p.rapidapi.com",
      'x-rapidapi-key': api_key
      }

  details = requests.request("GET", url, headers=headers, params=querystring)
  details = details.json()
  time.sleep(1.5)
  property_info.append(details)

property_info =pd.json_normalize(data=property_info)

print(len(property_info))
property_info.head(9)

property_info_csv=property_info.to_csv(f"Zillow Multi-family houses for {search_str}.csv")
files.download(f"Zillow Multi-family houses for {search_str}.csv")